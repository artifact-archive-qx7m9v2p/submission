# Model Critique for Experiment 1: Log-Linear Negative Binomial

**Model**: Log-Linear Negative Binomial Regression
**Date**: 2025-10-29
**Status**: COMPREHENSIVE FAILURE

---

## Executive Summary

The log-linear negative binomial model exhibits **fundamental misspecification** that cannot be remedied through minor adjustments. While the model demonstrates excellent computational properties and recovers parameters correctly under the assumed structure, it **systematically fails to capture the true data-generating process**.

**Key Finding**: The data exhibit accelerating exponential growth (super-exponential growth) that cannot be captured by a constant exponential growth rate model. This is evidenced by:
- Strong inverted-U curvature in residuals (quadratic coefficient = -5.22)
- 4.17× degradation in predictive accuracy between early and late periods
- Systematic underprediction in the final time periods

**Verdict**: The model class itself (log-linear in time) is fundamentally inadequate. This is not a fixable issue within the current model structure.

---

## Synthesis of All Validation Results

### 1. Prior Predictive Check: CONDITIONAL PASS

**Strengths**:
- Priors generate scientifically plausible data covering the observed range
- Appropriate uncertainty in all parameters
- No severe prior-data conflict
- Coverage: 96% for minimum, 80% for maximum

**Minor Concerns**:
- Some zero inflation (4.8 zeros per dataset vs. 0 observed)
- 2.6% of draws produce extreme values >10,000
- Both acceptable as prior uncertainty

**Assessment**: Priors are well-specified and appropriately uncertain. No issues here.

---

### 2. Simulation-Based Calibration: PASS WITH WARNINGS

**Strengths**:
- 100% computational success rate (50/50 simulations converged)
- Negligible bias: all parameters <0.04 SD from true values
- Excellent coverage: 88-92% (target: 80-95%)
- All R-hat <1.01, ESS >6000, zero divergences

**Minor Concerns**:
- Marginal rank non-uniformity for β₀ (p=0.035) and β₁ (p=0.023)
- Visual inspection shows bars within 95% confidence bands
- Likely finite-sample variation rather than fundamental problem

**Assessment**: Model correctly recovers known parameters under its own assumptions. The model structure is computationally sound and identifiable.

**Critical Implication**: This validates that **if the data were truly generated by a log-linear process**, the model would work perfectly. The fact that it fails on real data means **the real data are NOT log-linear**.

---

### 3. Posterior Inference: SUCCESS

**Convergence**:
- R-hat = 1.00 for all parameters
- ESS >6000 (target: >400)
- Zero divergent transitions
- Excellent chain mixing

**Parameter Estimates**:
- β₀ = 4.355 ± 0.049 (matches EDA: 4.30 ± 0.15)
- β₁ = 0.863 ± 0.050 (matches EDA: 0.85 ± 0.10)
- φ = 13.835 ± 3.449 (differs from naive EDA, but correct conditional estimate)

**Assessment**: Model fitting worked flawlessly. The model correctly identified the best log-linear approximation to the data. The issue is that a log-linear approximation is fundamentally inadequate.

---

### 4. Posterior Predictive Check: COMPREHENSIVE FAILURE

**Critical Failures** (3 of 4 falsification criteria violated):

#### a. Variance-to-Mean Recovery [FAIL]
- **Criterion**: 95% of Var/Mean ratios in [50, 90]
- **Result**: Only 67% in range; 95% CI [54.8, 130.9] extends to 131
- **Observed**: 68.7
- **Predicted**: 84.5 ± 20.1
- **Implication**: Model overestimates dispersion, producing overly wide prediction intervals

#### b. Late Period Degradation [FAIL]
- **Criterion**: Late/Early MAE ratio <2.0
- **Result**: Ratio = 4.17 (>2× threshold)
- **Early MAE**: 6.34 (years -1.67 to -0.90)
- **Late MAE**: 26.49 (years 0.98 to 1.67)
- **Implication**: Model fit deteriorates dramatically over time, indicating systematic misspecification

#### c. Systematic Curvature [FAIL]
- **Criterion**: |quadratic coefficient| <1.0
- **Result**: -5.22 (>5× threshold)
- **Pattern**: Clear inverted-U shape in residuals vs. time
- **Implication**: Linear-in-log-space assumption is violated; growth is accelerating

#### d. Coverage [PASS]
- **Criterion**: >80% coverage at 90% level
- **Result**: 100% (40/40 observations)
- **Caveat**: Over-conservative due to overestimated dispersion

---

## Assessment Against Falsification Criteria

From metadata.md, the model should be REJECTED if:

| Criterion | Threshold | Result | Status |
|-----------|-----------|--------|--------|
| 1. LOO-CV ΔELPD | >4 vs quadratic | Not yet computed | PENDING |
| 2. Systematic curvature | Inverted-U or U-shape | Inverted-U, coef=-5.22 | **VIOLATED** |
| 3. Late period failure | MAE ratio >2× | Ratio = 4.17× | **VIOLATED** |
| 4. Variance mismatch | 95% outside [50,90] | CI extends to 131 | **VIOLATED** |
| 5. Poor calibration | Coverage <80% | 100% coverage | PASSED |

**Result**: 3 of 5 criteria violated → **MODEL MUST BE REJECTED**

---

## Strengths of the Model

Despite the failures, the model has notable strengths:

1. **Computational Robustness**: Perfect convergence, no numerical issues, stable across parameter ranges
2. **Parameter Interpretability**: Clear meaning (β₁ = log-growth rate, exp(β₁) = multiplicative factor)
3. **Simplicity**: Only 3 parameters, easy to understand and communicate
4. **Baseline Value**: Provides a clear reference point for model comparison
5. **Conservative Uncertainty**: 100% coverage ensures no observations are missed
6. **Good Early-Period Fit**: MAE=6.34 in first 10 observations is reasonable

---

## Weaknesses and Critical Issues

### Critical Issue 1: Fundamental Misspecification of Growth Pattern

**Evidence**:
- Inverted-U residual curvature (quadratic coefficient = -5.22)
- Systematic underprediction in late period
- 4.17× increase in prediction error over time

**Root Cause**: The model assumes log(μ) = β₀ + β₁×year, which implies:
- μ(t) = exp(β₀) × exp(β₁×t)
- Constant proportional growth rate: dμ/dt / μ = β₁

The data violate this assumption - the proportional growth rate **increases over time**, suggesting:
- μ(t) ∝ exp(β₀ + β₁×t + β₂×t²) with β₂ >0, or
- A change-point in the growth rate, or
- A different functional form entirely

**Consequence**: This is not a minor deviation - it's a fundamental mismatch between model structure and data-generating process.

**Is it Fixable?**: NO, not within the log-linear model class. Requires a different model.

---

### Critical Issue 2: Deteriorating Predictive Performance

**Evidence**:
- Early period (first 10 obs): MAE = 6.34
- Late period (last 10 obs): MAE = 26.49
- Ratio: 4.17 (threshold: 2.0)

**Implication for Use Cases**:
- **Interpolation**: Acceptable in early period, poor in late period
- **Extrapolation**: Would be catastrophically bad (errors compound)
- **Forecasting**: Unreliable - would systematically underpredict future values
- **Scientific inference**: Misses key feature of the phenomenon (acceleration)

**Is it Fixable?**: NO, this is a consequence of Issue 1.

---

### Critical Issue 3: Overestimated Dispersion

**Evidence**:
- Predicted Var/Mean: 84.5 ± 20.1
- Observed Var/Mean: 68.7
- 95% CI [54.8, 130.9] extends beyond target [50, 90]

**Root Cause**: The model attributes systematic variation (due to misspecified trend) to random overdispersion. When the trend is wrong, residuals are larger, making φ appear to need more dispersion.

**Consequence**: Prediction intervals are too wide, reducing practical utility.

**Is it Fixable?**: Partially - a better trend specification would reduce residual variance, leading to more appropriate φ estimates.

---

## Pattern Recognition: What the Diagnostics Tell Us

### The Inverted-U Pattern

The inverted-U residual pattern is the **diagnostic signature** of systematic misspecification:

```
Early:  Model overpredicts   → Positive residuals
Middle: Model matches        → Near-zero residuals
Late:   Model underpredicts  → Negative residuals
```

This pattern occurs when:
- True function is convex (curving upward)
- Model fit is linear (straight line)
- Linear fit goes through the middle, misses the tails

**Interpretation**: The data "curve upward" (accelerate) faster than the model predicts.

---

### The 4× Degradation

The dramatic increase in late-period errors reveals that the misspecification **compounds over time**:

- Small errors early (model starts close to truth)
- Growing errors middle (divergence begins)
- Large errors late (model and data separate)

This is characteristic of **trend misspecification** - the cumulative effect of assuming the wrong functional form.

---

### The Over-Conservative Coverage

The fact that we achieve 100% coverage despite fundamental misspecification seems paradoxical, but reflects:

1. **Overestimated dispersion**: φ captures both random variation AND systematic error
2. **Wide posterior uncertainty**: β parameters have broad posteriors
3. **Compound effects**: Both sources of uncertainty widen prediction intervals

This is a case of "right answer for the wrong reason" - coverage is good, but intervals are uninformatively wide.

---

## Domain Considerations

### Scientific Context

The model describes count data with strong exponential growth. The finding that growth **accelerates** (super-exponential) has important scientific implications:

1. **Process Identification**: What mechanism could produce accelerating exponential growth?
   - Positive feedback loops
   - Network effects
   - Autocatalytic processes
   - Multiplicative advantage

2. **Forecasting**: Acceleration means:
   - Future growth will be faster than past growth
   - Simple exponential extrapolation will underestimate
   - Rapid transitions or phase changes may occur

3. **Intervention Points**: If growth is accelerating, interventions become more critical over time.

---

### Practical Decision-Making

For the intended scientific questions:

**NOT suitable for**:
- Forecasting beyond observed data (systematic underestimation)
- Understanding growth mechanisms (misses acceleration)
- Precise prediction in late periods (large errors)
- Resource planning requiring tight intervals

**Marginally suitable for**:
- Establishing that growth is non-linear (diagnostic value)
- Conservative bounds on future values (wide intervals)
- Early-period interpolation (MAE=6.34 acceptable)

---

## Comparison to Theoretical Expectations

The model was built on sound theoretical justification:
- Exponential growth is common in many domains
- EDA showed linear fit had R² = 0.92
- Negative binomial handles overdispersion

**So why did it fail?**

The EDA was **too coarse** - R² = 0.92 suggests good fit, but:
- R² measures overall variance explained
- Doesn't detect systematic patterns in residuals
- Can be high even with misspecification

The lesson: **Linear correlation is necessary but not sufficient** for model adequacy. Residual diagnostics are essential.

---

## Sensitivity Analysis

### Prior Sensitivity

The model used weakly informative priors:
- β₀ ~ Normal(4.3, 1.0)
- β₁ ~ Normal(0.85, 0.5)
- φ ~ Exponential(0.667)

**Assessment**: The posterior estimates (β₀=4.36, β₁=0.86) are very close to prior means, suggesting:
- Data are consistent with priors (no prior-data conflict)
- Priors may have been slightly too informative
- However, this is NOT the source of model failure

The curvature issue would persist even with completely flat priors - it's a structural problem, not a prior problem.

---

### Robustness Checks

**What if we:**
- Used wider priors? → Same curvature pattern would emerge
- Used different dispersion parameterization? → Wouldn't fix trend misspecification
- Removed outliers? → Pattern persists across all observations
- Used different time periods? → Late-period issues would remain

**Conclusion**: The failures are **robust to reasonable variations** - they reflect fundamental model inadequacy, not sensitivity to choices.

---

## Influential Observations

From the PPC plots:
- No single outlier drives the failures
- Residual pattern is smooth and systematic
- All 40 observations contribute to the curvature signal

**Assessment**: This is a **distributed problem**, not an influential-point problem. Removing any single observation would not resolve the misspecification.

---

## Calibration Quality

### Simulation-Based Calibration Results

The SBC showing 88-92% coverage with minimal bias tells us:
- **IF data were log-linear**, the model would work perfectly
- The model is **self-consistent** - it correctly captures its own assumptions
- The problem is that **real data don't follow the assumptions**

### Posterior Predictive Calibration Results

The 100% coverage but wide intervals tell us:
- Model is **over-cautious** due to misspecification
- Uncertainty is **inflated** to compensate for systematic error
- True calibration would be lower with a correctly specified model

---

## Model Complexity Assessment

Is the model too simple or too complex?

**Too Simple**: YES
- Missing quadratic term (or other flexibility)
- Cannot capture acceleration
- Only 3 parameters for 40 observations

**Too Complex**: NO
- All parameters are identifiable
- No overfitting (problems are underfitting)
- ESS is high (parameters are well-constrained)

**Conclusion**: The model is **parsimonious but inadequate**. More complexity is needed.

---

## Comparison to Alternative Models

While formal LOO-CV comparison is pending, we can anticipate:

### Quadratic Model (Experiment 2)
**Expected improvement**:
- Eliminates inverted-U curvature (adds β₂×year² term)
- Reduces late-period errors
- Better Var/Mean recovery
- LOO-CV likely shows ΔELPD >10 (strong evidence)

**Trade-offs**:
- One additional parameter (4 vs 3)
- Slightly reduced interpretability
- Worth it if curvature is substantial (it is)

---

## Files and Evidence

All validation results are documented in:

### Prior Predictive Check
- Location: `/workspace/experiments/experiment_1/prior_predictive_check/`
- Key file: `findings.md`
- Plots: 5 diagnostic plots
- Verdict: CONDITIONAL PASS

### Simulation-Based Validation
- Location: `/workspace/experiments/experiment_1/simulation_based_validation/`
- Key file: `recovery_metrics.md`
- Plots: 4 diagnostic plots
- Verdict: PASS WITH WARNINGS

### Posterior Inference
- Location: `/workspace/experiments/experiment_1/posterior_inference/`
- Key file: `inference_summary.md`
- Plots: 8 diagnostic plots
- Verdict: SUCCESS

### Posterior Predictive Check
- Location: `/workspace/experiments/experiment_1/posterior_predictive_check/`
- Key file: `ppc_findings.md`
- Plots: 7 diagnostic plots
- Verdict: FAIL (3/4 criteria violated)

---

## Conclusions

### What We Learned

1. **The model is computationally sound**: Perfect convergence, stable inference
2. **The model assumptions are violated**: Data are not log-linear
3. **The failures are systematic**: Inverted-U curvature, 4× error increase
4. **The failures are consequential**: Large errors, poor late-period performance
5. **The failures are not fixable**: Within current model structure

### What This Means

The log-linear negative binomial model serves as an excellent **baseline** that clearly demonstrates the need for more flexible growth specifications. It establishes:
- Lower bound on model performance
- Clear diagnostic evidence for what's missing (curvature)
- Strong justification for considering polynomial or alternative growth forms

### Key Insight

The most important finding is not that the model failed, but **HOW it failed**:
- Clear inverted-U pattern points to missing quadratic term
- Degrading performance over time indicates trend misspecification
- Overestimated dispersion suggests systematic error being captured as random variation

These diagnostics provide a **roadmap for improvement**.

---

## Recommendation Preview

**DECISION: REJECT**

This model is fundamentally misspecified and should be rejected in favor of a more flexible model class. The specific recommendation is to fit a quadratic model (log(μ) = β₀ + β₁×year + β₂×year²) as the next step.

Detailed justification and refinement plan are provided in the accompanying decision.md and improvement_priorities.md files.

---

**Critique completed**: 2025-10-29
**Analyst**: Model Criticism Specialist
**Next action**: Review decision.md for formal verdict
