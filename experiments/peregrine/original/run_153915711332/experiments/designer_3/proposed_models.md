# Bayesian Model Proposals: Designer 3
## Focus: Structural Hypotheses and Model Complexity

**Designer:** Model Designer 3
**Date:** 2025-10-29
**Data:** `/workspace/data/data_designer_3.csv`
**EDA Report:** `/workspace/eda/eda_report.md`

---

## Executive Summary

This document proposes three fundamentally different Bayesian model classes for the time series count data, emphasizing structural hypotheses about the data-generating process. Each model tests a specific scientific hypothesis about HOW the growth occurs, not just WHETHER it occurs.

### Critical EDA Findings Driving Model Design:
1. **Extreme overdispersion:** Var/Mean = 67.99 (rules out Poisson)
2. **Massive autocorrelation:** ACF(1) = 0.989 (near random walk)
3. **Strong evidence of changepoint:** At year ≈ 0.3 (4.5× jump in mean)
4. **Quadratic mean-variance relationship:** Suggests multiplicative processes
5. **Non-stationary:** I(1) process, first differences reduce variance 98%

### My Design Philosophy:
I will focus on **structural hypotheses** that explain the data-generating mechanism, not just statistical fits. Each model represents a different scientific story about what drives the exponential growth and extreme variability.

---

## Competing Hypotheses

Before proposing models, I identify three fundamentally different explanations for the observed patterns:

### Hypothesis 1: Regime Shift (Discrete Changepoint)
**Story:** The system underwent a fundamental structural change around year = 0.3, shifting from slow linear growth to rapid exponential growth. This could represent:
- A policy change or intervention
- A threshold effect (system reached critical mass)
- An external shock to the process

**Prediction:** We should see two distinct regimes with different growth dynamics and dispersion parameters.

**I will abandon this if:**
- The "changepoint" disappears when we use different binning
- Smooth models provide substantially better predictive performance
- Posterior predictive checks show the model generates unrealistic discontinuities

---

### Hypothesis 2: Smooth Acceleration (Gaussian Process)
**Story:** The growth accelerates smoothly over time without discrete breaks. The apparent "changepoint" is just the inflection point of a smooth nonlinear function. This could represent:
- Gradual compound growth (exponential of exponential)
- Smooth phase transition
- Natural S-curve dynamics (we're seeing the acceleration phase)

**Prediction:** A flexible nonparametric function should capture all structure without needing regime indicators.

**I will abandon this if:**
- The GP assigns high posterior probability to discontinuous functions
- Residuals show clear regime-specific patterns
- Model requires excessive smoothness penalties, suggesting it's fighting discrete structure

---

### Hypothesis 3: Latent State Evolution (State-Space)
**Story:** There's an unobserved latent state (e.g., "growth potential") that evolves over time, and observed counts are noisy realizations driven by this state. The extreme autocorrelation suggests counts at time t are directly generated by the state at time t, not by previous counts. This could represent:
- An underlying population size driving events
- A hidden capacity that grows deterministically
- A latent intensity process

**Prediction:** The latent state should evolve smoothly (possibly with trend + random walk), while observations show more variability.

**I will abandon this if:**
- The inferred latent state is just a smoothed version of observed data (adds no insight)
- Prior-posterior conflict on state variance parameters
- Computational difficulties (non-identifiability, divergences) suggest overparameterization

---

## Model Proposals

---

## MODEL 1: Hierarchical Changepoint Model (PRIORITY 1)

### Scientific Hypothesis
The data-generating process underwent a **discrete regime shift** at an unknown time point, with fundamentally different dynamics before and after the change. Each regime has its own growth rate, dispersion, and possibly different distributional parameters.

### Model Architecture

This is a **hierarchical Bayesian changepoint model** with:
- Unknown changepoint location (estimated from data)
- Regime-specific Negative Binomial parameters
- Hierarchical structure on regime parameters to borrow strength

### Full Probabilistic Specification

**Likelihood:**
```
For t = 1, ..., T:
  C_t ~ NegativeBinomial(mu_t, phi_regime[t])

  log(mu_t) = {
    beta0_1 + beta1_1 * year_t                    if year_t < tau
    beta0_2 + beta1_2 * (year_t - tau)            if year_t >= tau
  }

  regime[t] = 1 if year_t < tau, else 2
```

**Parameters:**
- `tau`: Changepoint location (year scale)
- `beta0_1, beta1_1`: Intercept and slope for regime 1
- `beta0_2, beta1_2`: Intercept and slope for regime 2
- `phi_1, phi_2`: Dispersion parameters for each regime
- `sigma_beta`: Hierarchical SD for beta coefficients

**Priors:**
```python
# Changepoint location (informed by EDA)
tau ~ Normal(0.3, 0.5)  # Centered on EDA finding, but allow uncertainty

# Hierarchical structure on growth rates
mu_beta ~ Normal(1.0, 1.0)  # Expected log-scale growth rate
sigma_beta ~ HalfNormal(1.0)

beta1_1 ~ Normal(mu_beta, sigma_beta)  # Regime 1 growth
beta1_2 ~ Normal(mu_beta, sigma_beta)  # Regime 2 growth

# Intercepts (weakly informative)
beta0_1 ~ Normal(3.5, 1.0)  # log(~33), close to early mean
beta0_2 ~ Normal(5.0, 1.0)  # log(~148), for continuity

# Dispersion parameters (expect overdispersion)
phi_1 ~ Gamma(2, 0.1)  # Mean = 20, SD = 14
phi_2 ~ Gamma(2, 0.1)  # Allow different dispersion in each regime

# Alternative: shared dispersion if we expect it's constant
# phi ~ Gamma(2, 0.1)
# phi_1 = phi_2 = phi
```

**Continuity Constraint (Optional):**
To ensure smooth transition at changepoint:
```python
# Enforce mu continuous at tau
beta0_2 = beta0_1 + beta1_1 * tau
```

**Log-Likelihood (for LOO):**
```python
def log_lik(C, mu, phi):
    """Negative Binomial log-likelihood"""
    return (
        gammaln(C + phi) - gammaln(phi) - gammaln(C + 1)
        + phi * log(phi / (phi + mu))
        + C * log(mu / (phi + mu))
    )
```

### Rationale from EDA

1. **Changepoint at year ≈ 0.3:** CUSUM analysis shows clear U-shaped pattern with minimum at year = 0.299. T-test confirms highly significant difference (p < 0.0001).

2. **Different regimes:** Mean jumps from 45.67 (before) to 205.12 (after), a 4.5× increase. Variance also increases substantially.

3. **Overdispersion in both regimes:** Even within each regime, variance far exceeds the mean, so we need Negative Binomial, not Poisson.

4. **Hierarchical structure:** With only 40 observations split across 2 regimes, hierarchical priors help regularize regime-specific parameters and prevent overfitting.

### What Hypotheses This Tests

1. **Structural break exists:** Is posterior for tau concentrated (supports changepoint) or diffuse (no clear break)?

2. **Different growth dynamics:** Is beta1_2 > beta1_1 (acceleration after break)?

3. **Regime-specific dispersion:** Is phi_2 different from phi_1? Higher dispersion post-break might indicate increased uncertainty.

4. **Changepoint location:** Is the EDA estimate of 0.3 robust, or does Bayesian inference shift it?

### Expected Computational Challenges

1. **Discontinuous likelihood:** Changepoint location tau creates discontinuous posterior. NUTS sampler may struggle with discrete switches.
   - **Solution:** Use reparameterization or marginalization over changepoint
   - **Alternative:** Sample tau from discrete grid, continuous parameters conditional on tau

2. **Label switching:** If priors are symmetric, regimes might switch labels.
   - **Solution:** Order constraint (e.g., beta0_2 > beta0_1)
   - **Check:** Trace plots for label consistency

3. **Posterior correlations:** tau, beta0_2, beta1_2 likely highly correlated (identifiability issues).
   - **Diagnostic:** Check Rhat, effective sample size
   - **Solution:** Non-centered parameterization

4. **Prior sensitivity:** Results may be sensitive to tau prior width.
   - **Required:** Prior predictive checks and sensitivity analysis

### Falsification Criteria: I Will Abandon This Model If...

1. **Changepoint is not identified:**
   - Posterior for tau is nearly uniform across the data range
   - Posterior SD for tau > 1.0 (more than half the data range)
   - **Action:** Switch to smooth model (Model 2)

2. **No evidence of different regimes:**
   - 95% credible intervals for beta1_1 and beta1_2 overlap substantially
   - Posterior predictive checks show smooth model generates similar data
   - **Action:** Simplify to single-regime exponential model

3. **Computational red flags:**
   - Rhat > 1.01 for key parameters after 4000+ iterations
   - Divergent transitions > 5% despite tuning
   - Effective sample size < 100 for tau
   - **Interpretation:** Model is too complex or misspecified

4. **Poor predictive performance:**
   - LOO-CV shows worse ELPD than smooth GP model (Model 2) by > 10 points
   - Posterior predictive checks show model generates unrealistic discontinuities
   - **Action:** Favor Model 2 or 3

5. **Prior-posterior conflict:**
   - Posterior for phi_1 or phi_2 is at extreme values (> 100 or < 1)
   - This suggests Negative Binomial is wrong; switch to different distribution
   - **Action:** Try Zero-Inflated NB or different dispersion model

### Model Variants to Explore

**Variant 1a: Unknown changepoint + smooth transition**
Replace hard switch with smooth sigmoid:
```python
weight = inv_logit(10 * (year - tau))  # Steepness = 10
log(mu) = (1 - weight) * (beta0_1 + beta1_1 * year)
          + weight * (beta0_2 + beta1_2 * year)
```

**Variant 1b: Multiple changepoints**
If single changepoint insufficient, allow 2 changepoints:
```python
tau_1 ~ Normal(-0.5, 0.5)
tau_2 ~ Normal(0.5, 0.5)  # with constraint tau_2 > tau_1
# 3 regimes
```

**Variant 1c: Changepoint in dispersion only**
Test if changepoint affects dispersion, not mean trend:
```python
log(mu) = beta0 + beta1 * year + beta2 * year^2  # Smooth trend
phi = phi_1 if year < tau else phi_2  # Discrete dispersion change
```

### Implementation Notes (Stan)

```stan
data {
  int<lower=0> N;
  int<lower=0> C[N];
  vector[N] year;
}

parameters {
  real tau;  // Changepoint location
  real beta0_1;
  real beta1_1;
  real beta0_2;
  real beta1_2;
  real<lower=0> phi_1;
  real<lower=0> phi_2;
}

transformed parameters {
  vector[N] mu;
  vector[N] phi;

  for (t in 1:N) {
    if (year[t] < tau) {
      mu[t] = exp(beta0_1 + beta1_1 * year[t]);
      phi[t] = phi_1;
    } else {
      mu[t] = exp(beta0_2 + beta1_2 * (year[t] - tau));
      phi[t] = phi_2;
    }
  }
}

model {
  // Priors
  tau ~ normal(0.3, 0.5);
  beta0_1 ~ normal(3.5, 1.0);
  beta1_1 ~ normal(1.0, 1.0);
  beta0_2 ~ normal(5.0, 1.0);
  beta1_2 ~ normal(1.0, 1.0);
  phi_1 ~ gamma(2, 0.1);
  phi_2 ~ gamma(2, 0.1);

  // Likelihood
  C ~ neg_binomial_2(mu, phi);
}

generated quantities {
  vector[N] log_lik;
  vector[N] C_rep;

  for (t in 1:N) {
    log_lik[t] = neg_binomial_2_lpmf(C[t] | mu[t], phi[t]);
    C_rep[t] = neg_binomial_2_rng(mu[t], phi[t]);
  }
}
```

### Expected Outcomes

**If this hypothesis is correct:**
- Posterior for tau will be concentrated near 0.3 with SD < 0.2
- beta1_2 will be significantly larger than beta1_1
- Posterior predictive checks will show sharp transition matching data
- LOO-ELPD will be competitive with or better than smooth models

**If this hypothesis is wrong:**
- tau posterior will be diffuse or multimodal
- Residuals will still show smooth autocorrelation structure
- Model will be outperformed by GP or state-space alternatives

---

## MODEL 2: Gaussian Process with Negative Binomial Likelihood (PRIORITY 2)

### Scientific Hypothesis
The growth process is **smoothly accelerating** without discrete breaks. The apparent "changepoint" is an artifact of seeing only part of a smooth nonlinear trajectory. The underlying rate function is complex but continuous, best captured by a flexible nonparametric prior.

### Model Architecture

This is a **Gaussian Process (GP) model** with:
- GP prior on the log-intensity function
- Negative Binomial observation model
- Stationary kernel (squared exponential or Matern)
- Trend component to capture non-stationarity

### Full Probabilistic Specification

**Likelihood:**
```
C_t ~ NegativeBinomial(mu_t, phi)

log(mu_t) = f(year_t)

f ~ GP(m(year), k(year, year'))
```

**Mean function (trend):**
```python
# Option 1: Linear trend
m(year) = beta0 + beta1 * year

# Option 2: Quadratic trend (recommended based on EDA)
m(year) = beta0 + beta1 * year + beta2 * year^2

# Option 3: Zero mean (let GP capture everything)
m(year) = 0
```

**Covariance kernel:**
```python
# Squared Exponential (SE) kernel - smooth functions
k(year_i, year_j) = alpha^2 * exp(-rho^2 * (year_i - year_j)^2)

# Matern 3/2 kernel - less smooth, more flexible
k(year_i, year_j) = alpha^2 * (1 + sqrt(3) * r / ell) * exp(-sqrt(3) * r / ell)
  where r = |year_i - year_j|

# Recommended: SE + linear trend to separate global and local structure
```

**Parameters:**
- `beta0, beta1, beta2`: Mean function coefficients
- `alpha`: GP marginal standard deviation (amplitude)
- `rho` (or `ell`): Length scale parameter
- `phi`: Negative Binomial dispersion

**Priors:**
```python
# Mean function
beta0 ~ Normal(4.0, 1.0)  # log(~55), mid-range count
beta1 ~ Normal(1.0, 1.0)  # Expect positive growth
beta2 ~ Normal(0.0, 0.5)  # Weak prior on curvature

# GP hyperparameters
alpha ~ HalfNormal(1.0)  # Marginal SD of deviations from trend
rho ~ InvGamma(5, 5)     # Length scale, mean = 1.25
  # Alternative: rho ~ Normal(1.0, 0.5) truncated to (0, 3)

# Dispersion
phi ~ Gamma(2, 0.1)  # Expect overdispersion
```

**Prior Reasoning:**
- **alpha:** Controls how much GP deviates from trend. HalfNormal(1) allows deviations up to 2-3× on log scale.
- **rho:** Length scale ~1 means correlation extends over ~1 standardized time unit. InvGamma puts mass on moderate smoothness.
- **beta2:** Quadratic term prior is skeptical (centered at 0) but allows discovery if present.

**Log-Likelihood:**
```python
# Same as Model 1
log_lik[t] = neg_binomial_2_lpmf(C[t] | mu[t], phi)
```

### Rationale from EDA

1. **Smooth polynomial fits well:** EDA shows quadratic R² = 0.961, cubic R² = 0.976. This suggests smooth functions are appropriate.

2. **CUSUM pattern:** The U-shape could be the natural curvature of a smooth acceleration, not a discrete break.

3. **Strong autocorrelation:** ACF(1) = 0.989. GP naturally induces correlation through the covariance kernel.

4. **Heteroscedasticity:** GP on log scale naturally allows variance to increase with mean.

5. **Uncertain about functional form:** We don't know if exponential, quadratic, cubic, etc. GP lets data choose.

### What Hypotheses This Tests

1. **Smoothness of growth:** How smooth is the optimal kernel? High rho = very smooth, low rho = wiggly.

2. **Need for flexibility:** Is posterior for f(year) close to a simple parametric form (quadratic)? If yes, we're overfitting.

3. **Local vs global structure:** Does GP capture local features or just global trend? Check posterior mean of f vs trend component.

4. **Changepoint vs acceleration:** If GP posterior shows discontinuity at year ≈ 0.3, changepoint model is better. If smooth, we win.

### Expected Computational Challenges

1. **GP scaling:** With N=40, computing N×N covariance matrix is fine (40³ = 64K operations). But Stan's GP implementations can be slow.
   - **Solution:** Use built-in GP functions in Stan (gp_exp_quad_cov)
   - **Alternative:** Hilbert space approximation for faster sampling

2. **Posterior correlations:** GP latent values f are highly correlated with hyperparameters alpha, rho.
   - **Diagnostic:** Check trace plots, Rhat
   - **Solution:** Non-centered parameterization: f = m + L * eta, where L = cholesky(K)

3. **Length scale identification:** With only 40 points, rho may be poorly identified.
   - **Check:** Prior vs posterior for rho
   - **Risk:** If posterior = prior, we haven't learned anything
   - **Solution:** Informative prior based on data range

4. **Kernel choice:** SE kernel may be too smooth for changepoint-like behavior.
   - **Test:** Compare SE vs Matern 3/2 vs Matern 5/2
   - **Diagnostic:** If Matern preferred, suggests less smooth truth

### Falsification Criteria: I Will Abandon This Model If...

1. **GP posterior shows discontinuity:**
   - Posterior draws of f(year) have sharp jumps at consistent locations
   - Posterior for rho concentrates at very small values (< 0.1), indicating no smooth structure
   - **Action:** This is evidence FOR changepoint model (Model 1)

2. **GP reduces to simple parametric form:**
   - Posterior for f(year) is nearly linear or quadratic
   - GP contribution (f - trend) has posterior SD < 0.1 everywhere
   - **Interpretation:** We're overfitting; a simple polynomial would suffice
   - **Action:** Use simpler exponential/polynomial Negative Binomial GLM

3. **Poor out-of-sample predictions:**
   - LOO-CV is worse than changepoint model by > 10 ELPD
   - Posterior predictive intervals are too wide (GP is too uncertain)
   - **Action:** Favor more structured model (Model 1 or 3)

4. **Computational failure:**
   - Cannot achieve Rhat < 1.01 after 8000+ iterations
   - Effective sample size for hyperparameters < 50
   - **Interpretation:** Model is too complex for N=40
   - **Action:** Simplify to parametric model

5. **Prior-posterior conflict on hyperparameters:**
   - Posterior for rho is at boundary of prior support
   - Posterior for alpha > 3 (extreme variability)
   - **Action:** Reconsider GP as appropriate model class

### Model Variants to Explore

**Variant 2a: GP with linear trend (simpler)**
```python
m(year) = beta0 + beta1 * year
# Let GP capture all nonlinearity
```

**Variant 2b: GP with zero mean (maximum flexibility)**
```python
m(year) = 0
# GP does everything, including trend
```

**Variant 2c: Different kernels**
```python
# Matern 3/2 (less smooth)
# Rational Quadratic (mixture of length scales)
# Periodic + SE (if we suspect cycles, unlikely here)
```

**Variant 2d: Sparse GP (for scalability)**
```python
# Use inducing points if we want to extend to larger N
# Not necessary for N=40, but good practice
```

### Implementation Notes (Stan)

```stan
data {
  int<lower=0> N;
  int<lower=0> C[N];
  vector[N] year;
}

transformed data {
  // Centering for numerical stability
  real year_mean = mean(year);
  vector[N] year_centered = year - year_mean;
}

parameters {
  real beta0;
  real beta1;
  real beta2;
  real<lower=0> alpha;  // GP amplitude
  real<lower=0> rho;    // GP length scale
  real<lower=0> phi;    // NB dispersion
  vector[N] eta;        // Non-centered GP
}

transformed parameters {
  vector[N] f;
  vector[N] mu;

  {
    matrix[N, N] L_K;
    matrix[N, N] K = gp_exp_quad_cov(year_centered, alpha, rho);

    // Add jitter for numerical stability
    for (n in 1:N) K[n, n] = K[n, n] + 1e-9;

    L_K = cholesky_decompose(K);
    f = L_K * eta;  // Non-centered parameterization
  }

  // Mean function + GP
  for (t in 1:N) {
    mu[t] = exp(beta0 + beta1 * year_centered[t] + beta2 * year_centered[t]^2 + f[t]);
  }
}

model {
  // Priors
  beta0 ~ normal(4.0, 1.0);
  beta1 ~ normal(1.0, 1.0);
  beta2 ~ normal(0.0, 0.5);
  alpha ~ normal(0, 1);  // Half-normal via truncation
  rho ~ inv_gamma(5, 5);
  phi ~ gamma(2, 0.1);
  eta ~ std_normal();  // Non-centered

  // Likelihood
  C ~ neg_binomial_2(mu, phi);
}

generated quantities {
  vector[N] log_lik;
  vector[N] C_rep;

  for (t in 1:N) {
    log_lik[t] = neg_binomial_2_lpmf(C[t] | mu[t], phi);
    C_rep[t] = neg_binomial_2_rng(mu[t], phi);
  }
}
```

### Expected Outcomes

**If this hypothesis is correct:**
- Posterior for f(year) will be smooth without discontinuities
- Length scale rho will be moderate (0.5 - 2.0)
- GP component will add meaningful structure beyond trend
- Posterior predictive checks will show smooth acceleration matching data
- May outperform changepoint model in LOO-CV

**If this hypothesis is wrong:**
- Posterior will reveal jump discontinuity at year ≈ 0.3
- rho will be very small (no spatial correlation) or very large (reduces to trend)
- Model will be outperformed by simpler alternatives

---

## MODEL 3: Latent State-Space Model with Stochastic Trend (PRIORITY 3)

### Scientific Hypothesis
The observed counts are **noisy realizations of an underlying latent process** (a hidden "growth potential" or "intensity state"). This latent state evolves smoothly over time according to a stochastic trend, while observations add additional overdispersion. The extreme autocorrelation (0.989) reflects the smooth evolution of the latent state, not direct dependence between observed counts.

### Model Architecture

This is a **Bayesian state-space model** with:
- Latent state evolving via local linear trend (random walk with drift)
- Negative Binomial observation model
- Separate variance components for state evolution vs observation noise

### Full Probabilistic Specification

**State Equation (Evolution):**
```
# Level equation
theta_t = theta_{t-1} + delta_{t-1} + w_t
w_t ~ Normal(0, sigma_w^2)

# Trend equation
delta_t = delta_{t-1} + v_t
v_t ~ Normal(0, sigma_v^2)

# Initial conditions
theta_1 ~ Normal(mu_0, sigma_0)
delta_1 ~ Normal(delta_0, tau_0)
```

**Observation Equation:**
```
C_t ~ NegativeBinomial(mu_t, phi)
log(mu_t) = theta_t
```

**Alternative (simpler): Random Walk on Log Intensity**
```
theta_t = theta_{t-1} + gamma + w_t
w_t ~ Normal(0, sigma_w^2)
theta_1 ~ Normal(mu_0, sigma_0)

C_t ~ NegativeBinomial(exp(theta_t), phi)
```

**Parameters:**
- `theta_t`: Latent log-intensity at time t (N-dimensional)
- `delta_t`: Latent trend component (if using local linear trend)
- `sigma_w`: SD of level innovations
- `sigma_v`: SD of trend innovations (if using local linear trend)
- `gamma`: Drift term (if using simple random walk)
- `phi`: Negative Binomial dispersion
- Initial state parameters

**Priors:**
```python
# Initial state
mu_0 ~ Normal(3.5, 1.0)  # log(~33), first observation
sigma_0 ~ HalfNormal(0.5)  # Uncertain about initial state

# Trend (for local linear trend model)
delta_0 ~ Normal(0.1, 0.1)  # Expect positive drift
tau_0 ~ HalfNormal(0.1)

# Innovation SDs (key parameters!)
sigma_w ~ HalfNormal(0.2)  # Level innovations
sigma_v ~ HalfNormal(0.05) # Trend innovations (expect smaller)

# Drift (for simple RW model)
gamma ~ Normal(0.15, 0.05)  # Based on mean growth rate from EDA

# Dispersion
phi ~ Gamma(2, 0.1)
```

**Prior Reasoning:**
- **sigma_w, sigma_v:** These control how much the latent state can change. Small values = smooth evolution (consistent with ACF=0.989). Too large = random noise.
- **gamma:** Mean period-over-period growth in EDA is 7.7%, which is ~0.074 on log scale. We use 0.15 to allow for compounding.
- **Initial state:** Start near observed first value but allow uncertainty.

**Log-Likelihood:**
```python
# Same as Models 1 and 2
log_lik[t] = neg_binomial_2_lpmf(C[t] | exp(theta[t]), phi)
```

### Rationale from EDA

1. **Extreme autocorrelation:** ACF(1) = 0.989 suggests a nearly deterministic evolution of some underlying process, with observations being noisy.

2. **Random walk structure:** Lag-1 regression shows slope ≈ 1.011, very close to random walk. First differencing achieves stationarity (variance drops 98%).

3. **Separating signal from noise:** Variance within short periods is much smaller than long-term growth. This suggests a smooth latent process with observation-level noise.

4. **I(1) process:** EDA confirms series is integrated. State-space models naturally handle non-stationary processes.

5. **Heteroscedasticity:** State-space allows both state variance (sigma_w) and observation variance (phi) to be estimated separately.

### What Hypotheses This Tests

1. **Latent vs observed dynamics:** Is there a meaningful distinction between the latent state evolution and observation noise?

2. **Smoothness of underlying process:** How smooth is theta_t? Small sigma_w = very smooth, large sigma_w = similar to observed data.

3. **Stochastic vs deterministic trend:** Is delta_t (trend) constant or time-varying? Compare sigma_v ≈ 0 (deterministic) vs sigma_v > 0 (stochastic).

4. **Source of autocorrelation:** Does accounting for latent state eliminate autocorrelation in residuals?

### Expected Computational Challenges

1. **High-dimensional latent space:** With N=40, we have 40 latent states + trend components = 80+ parameters.
   - **Challenge:** Posterior correlations between theta_t and theta_{t+1}
   - **Solution:** Non-centered parameterization, use QR decomposition
   - **Diagnostic:** Effective sample size for theta should be > 100

2. **Identification issues:** sigma_w and phi are not separately identified without strong priors.
   - **Problem:** State variance vs observation variance are confounded
   - **Solution:** Informative priors based on signal-to-noise ratio
   - **Check:** Prior predictive distributions

3. **Sampler efficiency:** Sequential dependency in state evolution can slow mixing.
   - **Expected:** Longer warmup needed, possibly 2000+ iterations
   - **Solution:** Increase adapt_delta to 0.95 or 0.99
   - **Monitor:** Divergent transitions

4. **Prior sensitivity:** Results highly sensitive to sigma_w and sigma_v priors.
   - **Required:** Sensitivity analysis with multiple prior specifications
   - **Check:** Does posterior fall within prior support, or hit boundaries?

### Falsification Criteria: I Will Abandon This Model If...

1. **Latent state is trivial:**
   - Posterior mean of theta_t is just smoothed observed log(C_t)
   - Correlation between theta_t and log(C_t) > 0.99
   - **Interpretation:** Model adds no scientific insight
   - **Action:** Use simpler direct models (Model 1 or 2)

2. **State variance not identified:**
   - Posterior for sigma_w is nearly identical to prior (no learning)
   - Or sigma_w concentrates at boundary (0 or very large)
   - **Interpretation:** Over-parameterized, not identifiable
   - **Action:** Switch to simpler model class

3. **No improvement over direct AR model:**
   - A simple AR(1) Negative Binomial model fits as well
   - State-space adds complexity without better predictions
   - **Action:** Use simpler autoregressive GLM

4. **Computational failure:**
   - Rhat > 1.05 for latent states after 8000 iterations
   - Divergent transitions > 10% despite max_treedepth=15, adapt_delta=0.99
   - **Interpretation:** Model is pathological for this data
   - **Action:** Abandon state-space approach

5. **Prior-posterior conflict:**
   - Posterior for sigma_w or sigma_v at extreme values (> 1.0 or < 0.01)
   - Suggests model structure is wrong
   - **Action:** Reconsider model specification

6. **Poor predictive performance:**
   - LOO-ELPD is much worse than Model 1 or 2 (> 20 points)
   - Posterior predictive checks fail (generates unrealistic data)
   - **Action:** This is not the right model class

### Model Variants to Explore

**Variant 3a: Simple Random Walk (recommended starting point)**
```python
theta_t = theta_{t-1} + gamma + w_t
# Simpler than local linear trend, fewer parameters
```

**Variant 3b: Local Linear Trend (more flexible)**
```python
theta_t = theta_{t-1} + delta_{t-1} + w_t
delta_t = delta_{t-1} + v_t
# Allows time-varying growth rate
```

**Variant 3c: Deterministic Trend + Stationary AR(1)**
```python
theta_t = beta0 + beta1 * t + z_t
z_t = phi_ar * z_{t-1} + w_t
# Separates deterministic trend from stationary deviations
```

**Variant 3d: Stochastic Volatility in State Equation**
```python
theta_t = theta_{t-1} + gamma + sigma_t * w_t
log(sigma_t) = log(sigma_{t-1}) + v_t
# Allows changing state variance over time
```

### Implementation Notes (Stan)

```stan
data {
  int<lower=0> N;
  int<lower=0> C[N];
  vector[N] year;  // Not used in model, but kept for consistency
}

parameters {
  real mu_0;             // Initial state mean
  real<lower=0> sigma_0; // Initial state SD
  real gamma;            // Drift
  real<lower=0> sigma_w; // State innovation SD
  real<lower=0> phi;     // NB dispersion
  vector[N] eta;         // Non-centered latent state innovations
}

transformed parameters {
  vector[N] theta;  // Latent log-intensity
  vector[N] mu;     // Expected counts

  // Initialize
  theta[1] = mu_0 + sigma_0 * eta[1];

  // Random walk evolution
  for (t in 2:N) {
    theta[t] = theta[t-1] + gamma + sigma_w * eta[t];
  }

  // Observation mean
  mu = exp(theta);
}

model {
  // Priors
  mu_0 ~ normal(3.5, 1.0);
  sigma_0 ~ normal(0, 0.5);  // Half-normal via truncation
  gamma ~ normal(0.15, 0.05);
  sigma_w ~ normal(0, 0.2);  // Half-normal
  phi ~ gamma(2, 0.1);
  eta ~ std_normal();  // Non-centered

  // Likelihood
  C ~ neg_binomial_2(mu, phi);
}

generated quantities {
  vector[N] log_lik;
  vector[N] C_rep;

  for (t in 1:N) {
    log_lik[t] = neg_binomial_2_lpmf(C[t] | mu[t], phi);
    C_rep[t] = neg_binomial_2_rng(mu[t], phi);
  }
}
```

**For Local Linear Trend (Variant 3b):**
```stan
parameters {
  // ... same as above, plus:
  real delta_0;
  real<lower=0> tau_0;
  real<lower=0> sigma_v;
  vector[N] eta_delta;
}

transformed parameters {
  vector[N] theta;
  vector[N] delta;
  vector[N] mu;

  // Initialize
  theta[1] = mu_0 + sigma_0 * eta[1];
  delta[1] = delta_0 + tau_0 * eta_delta[1];

  // Local linear trend evolution
  for (t in 2:N) {
    delta[t] = delta[t-1] + sigma_v * eta_delta[t];
    theta[t] = theta[t-1] + delta[t-1] + sigma_w * eta[t];
  }

  mu = exp(theta);
}
```

### Expected Outcomes

**If this hypothesis is correct:**
- Latent state theta_t will be smoother than observed log(C_t)
- sigma_w will be small (< 0.2), indicating smooth evolution
- Posterior for phi will be well-identified (separate from sigma_w)
- Residuals (C_t - mu_t) will show no autocorrelation
- One-step-ahead predictions will be excellent (using theta_{t-1} to predict C_t)

**If this hypothesis is wrong:**
- theta_t will just track observed data (no signal extraction)
- Large posterior uncertainty on sigma_w (not identified)
- No better than direct AR(1) model on log(C)
- Computational difficulties will emerge

---

## Model Comparison Strategy

### Stage 1: Initial Fitting (All Three Models in Parallel)

Fit all three models with default settings:
- Model 1: Changepoint model
- Model 2: GP with quadratic trend
- Model 3: State-space with simple RW

**Diagnostics:**
- Check Rhat < 1.01 for all parameters
- Effective sample size > 100 for key parameters
- No divergent transitions (or < 1%)
- Trace plots show good mixing

**Initial Comparison:**
- LOO-CV: Compare ELPD and SE
- WAIC: As alternative IC
- Posterior predictive checks: Visual inspection

### Stage 2: Model-Specific Refinement

Based on Stage 1 results, refine the most promising models:
- If Model 1 best: Try smooth transition variant (1a)
- If Model 2 best: Try different kernels (Matern 3/2)
- If Model 3 best: Try local linear trend variant (3b)

### Stage 3: Falsification Tests

For each model, conduct stress tests:

**Model 1 (Changepoint):**
- Sensitivity to tau prior
- Leave-one-out at the changepoint (does model fail?)
- Posterior predictive: Does it generate unrealistic jumps?

**Model 2 (GP):**
- Check if rho is identified (prior vs posterior)
- Does posterior for f show discontinuities?
- Compare to simple quadratic NB GLM

**Model 3 (State-space):**
- Is latent state just smoothed data?
- One-step-ahead prediction vs full model
- Compare to AR(1) NB model

### Stage 4: Final Decision

**Decision Criteria:**
1. **Statistical fit:** LOO-ELPD (primary), WAIC (secondary)
2. **Predictive performance:** Posterior predictive checks, coverage
3. **Computational health:** Rhat, ESS, divergences
4. **Scientific interpretability:** Does model tell coherent story?
5. **Parsimony:** Prefer simpler if fit is similar (ΔELPD < 4)

**Stopping Rules:**
- If all models have Rhat > 1.01 after 8000 iterations: Data may not support Bayesian inference, consider frequentist
- If all models fail posterior predictive checks: None of these model classes are appropriate
- If LOO-ELPD differences < 4: Models are equivalent, choose simplest (likely Model 1)

---

## Red Flags and Decision Points

### Red Flags That Would Trigger Major Pivot

1. **All three models show poor posterior predictive fit**
   - **Interpretation:** None of these model classes capture the data-generating process
   - **Action:** Consider fundamentally different approaches:
     - Zero-inflated models (if we misidentified zeros)
     - Conway-Maxwell-Poisson (if dispersion structure is wrong)
     - Discrete state HMM (if there are multiple hidden states)

2. **Negative Binomial consistently inadequate**
   - **Sign:** phi posterior at extreme values (< 1 or > 100) in all models
   - **Action:** Try different observation distributions:
     - Generalized Poisson
     - Poisson-lognormal mixture
     - Quasi-Poisson with robust estimation

3. **Strong evidence against all smooth models (Model 2 & 3)**
   - **Interpretation:** Changepoint is real and discrete
   - **Action:** Focus on Model 1 variants, possibly multiple changepoints

4. **Strong evidence against changepoint (Model 1 fails)**
   - **Interpretation:** Growth is smooth
   - **Action:** Focus on Model 2 or simpler parametric alternatives

5. **Computational issues across all models**
   - **Sign:** Divergences, poor Rhat, low ESS in all three
   - **Interpretation:** Models are too complex for N=40, or data is pathological
   - **Action:** Simplify to frequentist GLMs or simpler Bayesian models

### Decision Points (When to Stop and Reconsider)

**Decision Point 1: After Stage 1 (Initial Fits)**
- **Check:** Are any models clearly superior (ΔELPD > 10)?
- **If yes:** Focus on that model class, explore variants
- **If no:** All models are competitive, need deeper investigation

**Decision Point 2: After Stage 2 (Refinement)**
- **Check:** Has refinement improved the leading model?
- **If yes:** Proceed to validation
- **If no:** May indicate we've hit the limit of model improvement, check for overfitting

**Decision Point 3: After Stage 3 (Falsification)**
- **Check:** Has any model passed all stress tests?
- **If yes:** This is our final model
- **If no:** May need to combine models (Bayesian model averaging) or accept uncertainty

---

## Implementation Priority and Timeline

### Priority 1: Changepoint Model (Model 1)
**Time estimate:** 2-3 hours (coding + diagnostics)
**Rationale:** Strongest evidence from EDA, most interpretable
**Risk:** May be too simplistic if changepoint is artifact

### Priority 2: Gaussian Process (Model 2)
**Time estimate:** 3-4 hours (GP can be tricky in Stan)
**Rationale:** Flexible, handles uncertainty about functional form
**Risk:** May overfit with N=40, computational challenges

### Priority 3: State-Space Model (Model 3)
**Time estimate:** 4-5 hours (most complex, debugging likely)
**Rationale:** Most sophisticated, best handles autocorrelation
**Risk:** Over-parameterized, identification issues, computational cost

### Parallel Development Strategy

1. **Day 1:** Implement all three models in simplified form
2. **Day 2:** Diagnose issues, refine priors, ensure convergence
3. **Day 3:** LOO comparison, posterior predictive checks
4. **Day 4:** Stress tests, sensitivity analysis, final decision

---

## Alternative Approaches If All Three Models Fail

### Backup Plan A: Simpler Parametric Models
If complex models are over-fitting or failing to converge:
- NB GLM with quadratic trend (no GP, no changepoint)
- NB GLM with exponential trend: log(mu) = beta0 + beta1 * year
- Quasi-Poisson regression as simpler alternative

### Backup Plan B: Frequentist Alternatives
If Bayesian inference is too challenging:
- Generalized Estimating Equations (GEE) with AR(1) correlation
- NB GLM with robust standard errors
- Time series ARIMA on log(C) or differenced counts

### Backup Plan C: Diagnostic-Driven Modeling
If models show specific failure patterns:
- If extreme outliers found: Robust regression (t-distributed errors)
- If zeros are the issue: Hurdle or ZIP models
- If multimodality in counts: Finite mixture models

---

## Summary Table: Model Comparison

| Model | Hypothesis | Key Strength | Key Weakness | Falsification Criterion | Priority |
|-------|------------|--------------|--------------|-------------------------|----------|
| **1. Changepoint** | Discrete regime shift | Direct test of EDA finding, interpretable | May miss smooth structure | tau posterior diffuse | 1 |
| **2. Gaussian Process** | Smooth acceleration | Flexible, minimal assumptions | Computational cost, overfitting risk | Posterior shows jumps | 2 |
| **3. State-Space** | Latent process evolution | Handles autocorrelation naturally | Identification issues, complexity | Latent state = observed data | 3 |

---

## Expected Parameter Ranges (For Validation)

Based on EDA, posterior estimates should be approximately:

| Parameter | Expected Range | Interpretation |
|-----------|---------------|----------------|
| log(mu) at year=-1.67 | [3.0, 3.8] | log(20-45), early period mean |
| log(mu) at year=1.67 | [5.2, 5.7] | log(180-300), late period mean |
| phi (dispersion) | [5, 50] | Overdispersion moderate to high |
| tau (changepoint) | [0.0, 0.5] | Near EDA estimate of 0.3 |
| sigma_w (state SD) | [0.05, 0.3] | Small (smooth state evolution) |
| alpha (GP amplitude) | [0.3, 1.5] | Moderate deviations from trend |
| rho (GP length scale) | [0.5, 2.0] | Moderate smoothness |

**If posteriors are outside these ranges:** Investigate why. May indicate model misspecification or prior issues.

---

## Final Notes

### What Success Looks Like

1. **At least one model** achieves Rhat < 1.01 for all parameters
2. **LOO-ELPD** provides clear ranking or shows equivalence
3. **Posterior predictive checks** show model can generate data similar to observed
4. **Falsification tests** clearly reject at least one model class
5. **Scientific story** emerges: Which hypothesis is best supported?

### What Failure Looks Like

1. **All models fail to converge** (Rhat > 1.01)
2. **Extreme posterior values** (phi > 100, sigma_w > 1, etc.)
3. **LOO completely fails** (Pareto k > 0.7 for many points)
4. **No model passes posterior predictive checks**

**If we fail:** This is valuable information! It means:
- Data is more complex than anticipated
- N=40 is insufficient for these model classes
- Frequentist methods may be more appropriate
- Or we need domain expertise to constrain the problem

### Key Insight

The goal is **not** to force one of these three models to work. The goal is to **discover the truth** about the data-generating process. If all three fail, that's a success in scientific inference—we've learned what doesn't work and can pivot to better approaches.

---

## Files and Code

All model implementations will be saved to:
- `/workspace/experiments/designer_3/models/model_1_changepoint.stan`
- `/workspace/experiments/designer_3/models/model_2_gaussian_process.stan`
- `/workspace/experiments/designer_3/models/model_3_state_space.stan`

Fitting scripts:
- `/workspace/experiments/designer_3/fit_models.py` (main script)
- `/workspace/experiments/designer_3/diagnostics.py` (convergence checks)
- `/workspace/experiments/designer_3/comparison.py` (LOO, WAIC, PPC)

Results:
- `/workspace/experiments/designer_3/results/model_comparison.csv`
- `/workspace/experiments/designer_3/results/posterior_summaries/`
- `/workspace/experiments/designer_3/results/visualizations/`

---

**End of Model Proposals**
**Designer 3 - Structural Hypotheses and Model Complexity Focus**
**Ready for implementation and testing**
