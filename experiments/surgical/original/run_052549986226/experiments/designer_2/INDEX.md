# Designer 2: Complete File Index

## Overview
This directory contains complete specifications and implementations for hierarchical binomial models with random effects, designed to address severe overdispersion (Ï† â‰ˆ 3.5-5.1) through group-level random effects on the logit scale.

---

## File Organization

### ğŸ“‹ Documentation (Start Here)

1. **`INDEX.md`** (this file)
   - Navigation guide to all files
   - Quick reference for what to read when

2. **`QUICK_START.md`** â­ START HERE
   - 5-minute quick start guide
   - Essential commands and expected outputs
   - Troubleshooting common issues
   - **Read this first if you want to run the models immediately**

3. **`README.md`**
   - Comprehensive overview of all three models
   - Design decisions and justifications
   - Usage instructions and examples
   - Success criteria and failure modes
   - **Read this for complete understanding**

4. **`proposed_models.md`** ğŸ“š DETAILED DESIGN
   - Full mathematical specifications
   - Detailed prior justifications
   - Falsification criteria for each model
   - Expected posterior behavior
   - Critical thinking about model failures
   - **Read this to understand the theoretical foundation**

5. **`MODEL_DECISION_TREE.md`** ğŸ—ºï¸ DECISION GUIDE
   - Flowchart for model selection
   - Decision points and thresholds
   - When to pivot to alternative models
   - Success/failure criteria matrix
   - **Read this when deciding which model to use**

---

### ğŸ’» Stan Model Implementations

6. **`model1_centered.stan`**
   - Centered parameterization: logit(p_i) = Î¼ + Î±_i
   - Standard hierarchical model structure
   - **Status:** Baseline, may have computational issues
   - **Use:** Demonstrating importance of reparameterization

7. **`model2_noncentered.stan`** â­ RECOMMENDED
   - Non-centered: logit(p_i) = Î¼ + ÏƒÂ·z_i
   - Eliminates funnel geometry
   - **Status:** Primary model for inference
   - **Use:** Most likely to converge reliably

8. **`model3_robust.stan`**
   - Student-t priors: z_i ~ Student-t(Î½, 0, 1)
   - Heavy tails for outlier robustness
   - **Status:** Sensitivity analysis
   - **Use:** Assessing impact of Group 8 outlier

---

### ğŸ Python Implementation Scripts

9. **`fit_models.py`** â­ MAIN FITTING SCRIPT
   - Fits all three models using CmdStanPy
   - Comprehensive MCMC diagnostics
   - Posterior summaries and checks
   - **Command:** `python fit_models.py --model 2`
   - **Runtime:** 2-5 minutes per model

10. **`model_comparison.py`**
    - Compares fitted models
    - LOO-CV analysis
    - Creates visualizations
    - Summary reports
    - **Command:** `python model_comparison.py`
    - **Runtime:** 2-3 minutes

---

## Reading Guide by Use Case

### ğŸ¯ "I just want to fit models and get results"
1. Read: `QUICK_START.md` (5 min)
2. Run: `python fit_models.py --model 2`
3. Check: Diagnostics in console output
4. Review: `results/*_summary.csv`

**Total time:** 15 minutes

---

### ğŸ”¬ "I want to understand the design"
1. Read: `README.md` (15 min)
2. Read: `proposed_models.md` (30 min)
3. Review: Stan files to see implementation
4. Check: Mathematical derivations in proposed_models.md

**Total time:** 1 hour

---

### ğŸ¤” "I'm deciding which model to use"
1. Read: `MODEL_DECISION_TREE.md` (10 min)
2. Run: `python fit_models.py --model all`
3. Run: `python model_comparison.py`
4. Review: `visualizations/comparison_report.txt`
5. Check: LOO-CV results and diagnostic comparisons

**Total time:** 30 minutes

---

### ğŸ› "Something went wrong"
1. Check: `QUICK_START.md` troubleshooting section
2. Review: Diagnostic output from `fit_models.py`
3. Check: `MODEL_DECISION_TREE.md` red flags section
4. Read: Falsification criteria in `proposed_models.md`
5. Consider: Switching to beta-binomial (Designer 1)

---

### ğŸ“Š "I need to compare with other designers"
1. Ensure: All models fitted successfully
2. Run: `python model_comparison.py`
3. Compare: LOO-CV scores across designers
4. Check: Stacking weights
5. Review: Predictive performance metrics

---

## Directory Structure (After Running)

```
experiments/designer_2/
â”‚
â”œâ”€â”€ Documentation
â”‚   â”œâ”€â”€ INDEX.md                      (this file)
â”‚   â”œâ”€â”€ QUICK_START.md               (5-min guide)
â”‚   â”œâ”€â”€ README.md                    (comprehensive)
â”‚   â”œâ”€â”€ proposed_models.md           (detailed design)
â”‚   â””â”€â”€ MODEL_DECISION_TREE.md       (decision guide)
â”‚
â”œâ”€â”€ Stan Models
â”‚   â”œâ”€â”€ model1_centered.stan         (baseline)
â”‚   â”œâ”€â”€ model2_noncentered.stan      (recommended)
â”‚   â””â”€â”€ model3_robust.stan           (outlier-robust)
â”‚
â”œâ”€â”€ Python Scripts
â”‚   â”œâ”€â”€ fit_models.py                (main fitting)
â”‚   â””â”€â”€ model_comparison.py          (comparison & viz)
â”‚
â”œâ”€â”€ Results (created after fitting)
â”‚   â”œâ”€â”€ M1_*_summary.csv
â”‚   â”œâ”€â”€ M1_*_diagnostics.json
â”‚   â”œâ”€â”€ M1_*_draws.csv
â”‚   â”œâ”€â”€ M2_*_summary.csv
â”‚   â”œâ”€â”€ M2_*_diagnostics.json
â”‚   â”œâ”€â”€ M2_*_draws.csv
â”‚   â”œâ”€â”€ M3_*_summary.csv
â”‚   â”œâ”€â”€ M3_*_diagnostics.json
â”‚   â””â”€â”€ M3_*_draws.csv
â”‚
â”œâ”€â”€ Visualizations (created after comparison)
â”‚   â”œâ”€â”€ comparison_report.txt        (summary text)
â”‚   â”œâ”€â”€ population_parameters_comparison.png
â”‚   â”œâ”€â”€ group_posteriors_comparison.png
â”‚   â”œâ”€â”€ shrinkage_comparison.png
â”‚   â”œâ”€â”€ overdispersion_check.png
â”‚   â”œâ”€â”€ group1_zero_count_shrinkage.png
â”‚   â”œâ”€â”€ nu_posterior.png             (if M3 fitted)
â”‚   â””â”€â”€ diagnostic_comparison.csv
â”‚
â””â”€â”€ Stan Output (temporary files)
    â””â”€â”€ model_*_*.csv
```

---

## Key Features of This Design

### âœ… Strengths
- **Principled shrinkage:** No ad-hoc corrections for zero counts
- **Interpretable:** Clear parameter meanings (Î¼, Ïƒ, Î±_i)
- **Flexible:** Can add group-level covariates
- **Robust:** Three variants for different scenarios
- **Well-tested:** Non-centered parameterization for reliability

### âš ï¸ Limitations
- **More complex:** 12 parameters vs 2 for beta-binomial
- **Computationally intensive:** Requires MCMC sampling
- **Assumes continuous distribution:** May fail if discrete subgroups
- **Logit scale:** Between-group SD not directly interpretable

---

## Model Summary Table

| Model | Parameterization | Prior on Ïƒ | Strengths | When to Use |
|-------|------------------|------------|-----------|-------------|
| **M1** | Centered | Half-Cauchy(0,1) | Standard, interpretable | Demonstrating funnel problem |
| **M2** | Non-centered | Half-Normal(0,1) | Efficient sampling | **Primary analysis** |
| **M3** | Non-centered + Student-t | Half-Student-t(3,0,1) | Outlier robust | **Sensitivity analysis** |

---

## Critical Design Decisions

### 1. Why Non-Centered (M2)?
- High ICC (0.73) â†’ strong shrinkage â†’ funnel geometry in centered
- Non-centered eliminates Ïƒ-Î± correlation
- Expected 10-100Ã— reduction in divergences

### 2. Why Logit Link?
- Natural for probabilities [0, 1]
- Group effects plausibly normal on logit scale
- Standard in binomial regression

### 3. How is Group 1 (0/47) Handled?
- **No continuity correction**
- Hierarchical shrinkage pulls toward Î¼
- Expected posterior: 1-3% (low but not zero)

### 4. Why Robust Model (M3)?
- Group 8 is extreme (z = 3.94)
- Heavy tails allow outliers without distortion
- Posterior Î½ tells if it was necessary

---

## Expected Results

### If Models Succeed:

**Population parameters:**
- Î¼ â‰ˆ -2.5 (7.5% on probability scale)
- Ïƒ â‰ˆ 0.9 (consistent with ICC = 0.73)
- Ï† â‰ˆ 3.5-5.1 (reproduces overdispersion)

**Group-specific:**
- Group 1: Shrink from 0% to ~2%
- Group 8: Shrink from 14.4% to ~11-12%
- Small-n groups shrink more

**Diagnostics:**
- Rhat < 1.01, ESS > 400, Divergences < 1%

### If Models Fail:

**Computational failure:** Switch to beta-binomial
**Statistical failure:** Can't reproduce Ï† â†’ Try mixture
**Outlier problems:** Multiple Pareto k > 0.7 â†’ Finite mixture

---

## Quick Reference Commands

```bash
# Fit recommended model (M2)
python fit_models.py --model 2

# Fit all models
python fit_models.py --model all

# Fit with higher adapt_delta (if divergences)
python fit_models.py --model 2 --adapt_delta 0.95

# Compare models
python model_comparison.py

# Check diagnostics quickly
grep "PASS\|FAIL" results/*_diagnostics.json
```

---

## Contact Points with Other Designers

### vs Designer 1 (Beta-Binomial)
- **Compare:** LOO-CV scores
- **Trade-off:** Complexity vs simplicity
- **Use hierarchical if:** Group-specific effects important
- **Use beta-binomial if:** Similar performance, more parsimonious

### vs Designer 3 (Alternative Approaches)
- **Compare:** LOO-CV and predictive checks
- **Consider:** Stacking weights if models competitive
- **Document:** Why hierarchical binomial chosen/rejected

---

## Success Criteria Checklist

Before declaring this approach successful:

- [ ] Rhat < 1.01 for all parameters
- [ ] ESS > 400 for all parameters
- [ ] Divergences < 1%
- [ ] Posterior Ï† âˆˆ [3.0, 6.0]
- [ ] Ïƒ âˆˆ [0.5, 1.5]
- [ ] Group 1 posterior â‰ˆ 1-3%
- [ ] LOO Pareto k < 0.7 for all groups
- [ ] Posterior predictive matches observed
- [ ] Compared to other designers
- [ ] Results scientifically interpretable

---

## Citation

If using this model design:

```
Hierarchical binomial model with non-centered parameterization
addressing severe overdispersion (Ï† â‰ˆ 3.5-5.1) through group-level
random effects. Handles zero counts via shrinkage without ad-hoc
corrections. Implemented in Stan via CmdStanPy.
```

Key references:
- Gelman & Hill (2007) for hierarchical models
- Stan manual for non-centered parameterization
- Williams (1982) for overdispersion in binomial data

---

## Final Recommendations

1. **Start with M2** (non-centered) - most likely to work
2. **Check diagnostics carefully** - don't trust results without verification
3. **Compare to Designer 1** - beta-binomial might be simpler
4. **Document failures** - negative results are valuable
5. **Be ready to pivot** - finding model inadequacy is success

**Remember:** The goal is finding truth, not completing tasks.

---

## Version Information

**Created:** 2025-10-30
**Designer:** Model Designer 2 (Hierarchical Binomial Focus)
**Data:** 12 groups, binomial trials, severe overdispersion
**Framework:** Bayesian hierarchical models via Stan/CmdStanPy

---

## Questions?

1. **What to read first?** â†’ `QUICK_START.md`
2. **Model not converging?** â†’ `MODEL_DECISION_TREE.md` troubleshooting
3. **Understanding the theory?** â†’ `proposed_models.md`
4. **Which model to use?** â†’ `MODEL_DECISION_TREE.md`
5. **Comparing designers?** â†’ Run `model_comparison.py`

---

**Good luck with the analysis! Remember: principled inference > completing predetermined plans.**
